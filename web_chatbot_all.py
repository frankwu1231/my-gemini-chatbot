import streamlit as st
import google.generativeai as genai
from gtts import gTTS
from PIL import Image
from streamlit_camera import camera_input # (æ–°å¢) åŒ¯å…¥ç›¸æ©Ÿå…ƒä»¶
import io
import base64

# --- 1. ç¶²é åŸºç¤é…ç½® ---
st.set_page_config(
    page_title="å…¨èƒ½ AI åŠ©ç† (æ–‡å­—/èªéŸ³/åœ–ç‰‡/æ”å½±)",
    page_icon="ğŸ“¸",
    layout="centered"
)

# --- èªéŸ³ç”Ÿæˆèˆ‡è‡ªå‹•æ’­æ”¾å‡½æ•¸ ---
def text_to_speech_autoplay(text: str, language_tld: str):
    try:
        tts = gTTS(text=text, lang='zh-TW', tld=language_tld, slow=False)
        audio_fp = io.BytesIO()
        tts.write_to_fp(audio_fp)
        audio_fp.seek(0)
        audio_base64 = base64.b64encode(audio_fp.read()).decode('utf-8')
        audio_html = f"""
        <audio autoplay>
            <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mpeg">
        </audio>
        """
        st.components.v1.html(audio_html, height=0)
    except Exception as e:
        st.error(f"èªéŸ³ç”Ÿæˆå¤±æ•—ï¼š{e}")

# --- 2. è¨­å®šå´é‚Šæ¬„ (Sidebar) ---
st.sidebar.header("âš™ï¸ æ ¸å¿ƒè¨­å®š")

# API Key è¨­å®š
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
except KeyError:
    api_key = None
if not api_key:
    st.sidebar.warning("å°šæœªè¨­å®š API Keyï¼è«‹åœ¨ Streamlit Cloud Secrets ä¸­è¨­å®šã€‚")
    api_key = st.sidebar.text_input("æˆ–åœ¨æ­¤è‡¨æ™‚è¼¸å…¥æ‚¨çš„ Google API Keyï¼š", type="password")

# è§’è‰²ç‰¹æ€§è¨­å®š
default_persona = "ä½ æ˜¯ä¸€ä½çŸ¥è­˜æ·µåšã€è§€å¯ŸåŠ›æ•éŠ³çš„ AI åŠ©ç†ã€‚"
st.sidebar.subheader("ğŸ­ è§’è‰²ç‰¹æ€§è¨­å®š")
persona_prompt = st.sidebar.text_area("è«‹è¼¸å…¥ AI çš„è§’è‰²æè¿° (System Prompt)ï¼š", value=default_persona, height=200)

# æ¨¡å‹é¸æ“‡
model_name = st.sidebar.selectbox("é¸æ“‡æ¨¡å‹ (Vision Pro æ”¯æ´åœ–ç‰‡/æ”å½±)", ("gemini-1.5-pro-latest", "gemini-1.5-flash-latest"))

# èªéŸ³åŠŸèƒ½è¨­å®š
st.sidebar.subheader("ğŸ”Š èªéŸ³è¨­å®š")
tts_enabled = st.sidebar.toggle("å•Ÿç”¨/é—œé–‰èªéŸ³è¼¸å‡º", value=True)
voice_options = {"å°ç£ - æ¨™æº–å¥³è²": "com.tw", "ç¾åœ‹ - è‹±èªå¥³è²": "us", "è‹±åœ‹ - è‹±èªå¥³è²": "co.uk"}
selected_voice_name = st.sidebar.selectbox("é¸æ“‡èªéŸ³", list(voice_options.keys()))
selected_voice_tld = voice_options[selected_voice_name]

# --- 3. ä¸»æ‡‰ç”¨ç¨‹å¼ä»‹é¢ ---
st.title("ğŸ“¸ å…¨èƒ½ AI åŠ©ç†")
st.caption("æ”¯æ´æ–‡å­—ã€èªéŸ³è¼¸å‡ºã€åœ–ç‰‡ä¸Šå‚³èˆ‡å³æ™‚æ”å½±")

# --- 4. åˆå§‹åŒ–æ¨¡å‹èˆ‡å°è©± ---
# (æ­¤å€å¡Šç¨‹å¼ç¢¼èˆ‡å‰ä¸€ç‰ˆå®Œå…¨ç›¸åŒï¼Œæ­¤è™•çœç•¥ä»¥ç¯€çœç¯‡å¹…)
chat = None
if not api_key:
    st.error("âš ï¸ è«‹åœ¨å·¦å´è¨­å®šæ‚¨çš„ Google API Keyã€‚")
elif not persona_prompt.strip():
    st.error("âš ï¸ è§’è‰²çš„ç‰¹æ€§è¨­å®šä¸èƒ½ç‚ºç©ºï¼")
else:
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name=model_name, system_instruction=persona_prompt)
        chat = model.start_chat(history=[])
        st.success("æ¨¡å‹å·²æˆåŠŸè¼‰å…¥ï¼")
    except Exception as e:
        st.error(f"æ¨¡å‹æˆ– API Key è¼‰å…¥å¤±æ•—ï¼š{e}")


# --- 5. å°è©±æ­·å²è¨˜éŒ„ç®¡ç† ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if "image" in message:
            st.image(message["image"], width=200)
        st.markdown(message["content"])

# --- (æ›´æ–°) åœ–ç‰‡/æ”å½±ä¸Šå‚³èˆ‡ç®¡ç† ---
st.subheader("åœ–ç‰‡/æ”å½±è¼¸å…¥")
# å°‡åœ–ç‰‡å’Œæ”å½±æ©Ÿè¼¸å…¥æ”¾åœ¨åˆ†é ä¸­ï¼Œè®“ä»‹é¢æ›´æ•´æ½”
tab1, tab2 = st.tabs(["ğŸ“ æª”æ¡ˆä¸Šå‚³", "ğŸ“· æ”å½±æ©Ÿæ‹ç…§"])

with tab1:
    uploaded_image = st.file_uploader("ä¸Šå‚³åœ–ç‰‡æª”æ¡ˆ...", type=["jpg", "jpeg", "png"], label_visibility="collapsed")

with tab2:
    camera_photo = camera_input(
        "é»æ“Šä¸‹æ–¹çš„ç›¸æ©Ÿåœ–ç¤ºæ‹ç…§", 
        key="camera_input",
        label_visibility="collapsed"
    )

# ç‹€æ…‹ç®¡ç†ï¼šå„ªå…ˆä½¿ç”¨ç›¸æ©Ÿç…§ç‰‡ï¼Œå…¶æ¬¡æ˜¯ä¸Šå‚³çš„æª”æ¡ˆ
if "image_data" not in st.session_state:
    st.session_state.image_data = None

if camera_photo:
    st.session_state.image_data = Image.open(camera_photo)
elif uploaded_image:
    st.session_state.image_data = Image.open(uploaded_image)

# å¦‚æœæœ‰åœ–ç‰‡ï¼Œå°±é¡¯ç¤ºå‡ºä¾†
if st.session_state.image_data:
    st.image(st.session_state.image_data, caption="å·²è¼‰å…¥åœ–ç‰‡", width=200)


# --- 6. è™•ç†ä½¿ç”¨è€…è¼¸å…¥èˆ‡æ¨¡å‹äº’å‹• ---
# (æ­¤å€å¡Šç¨‹å¼ç¢¼èˆ‡å‰ä¸€ç‰ˆå®Œå…¨ç›¸åŒ)
if prompt := st.chat_input("è«‹è¼¸å…¥æ–‡å­—æˆ–è¼‰å…¥åœ–ç‰‡å¾Œæå•..."):
    if chat:
        user_message_to_display = {"role": "user", "content": prompt}
        if st.session_state.image_data:
             user_message_to_display["image"] = st.session_state.image_data
        
        st.session_state.messages.append(user_message_to_display)
        with st.chat_message("user"):
            if st.session_state.image_data:
                st.image(st.session_state.image_data, width=200)
            st.markdown(prompt)

        model_input = [prompt]
        if st.session_state.image_data:
            model_input.append(st.session_state.image_data)
        
        st.session_state.image_data = None # æ¸…ç©ºåœ–ç‰‡ï¼Œé¿å…é‡è¤‡å‚³é€
        
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.markdown("æ€è€ƒä¸­...âœï¸")
            try:
                response = chat.send_message(model_input)
                full_response = response.text
                message_placeholder.markdown(full_response)
                if tts_enabled:
                    text_to_speech_autoplay(full_response, selected_voice_tld)
            except Exception as e:
                full_response = f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"
                message_placeholder.error(full_response)
        
        st.session_state.messages.append({"role": "assistant", "content": full_response})
    else:
        st.warning("è«‹å…ˆå®Œæˆå·¦å´çš„è¨­å®šæ‰èƒ½é–‹å§‹å°è©±ã€‚")