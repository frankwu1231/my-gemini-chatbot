import streamlit as st
import google.generativeai as genai
from gtts import gTTS
from PIL import Image
import io
import base64

# --- 1. ç¶²é åŸºç¤é…ç½® ---
st.set_page_config(
    page_title="å¤šåŠŸèƒ½ AI åŠ©ç† (æ–‡å­—/èªéŸ³/åœ–ç‰‡)",
    page_icon="âœ¨",
    layout="centered"
)

# --- èªéŸ³ç”Ÿæˆèˆ‡è‡ªå‹•æ’­æ”¾å‡½æ•¸ ---
def text_to_speech_autoplay(text: str, language_tld: str):
    try:
        tts = gTTS(text=text, lang='zh-TW', tld=language_tld, slow=False)
        audio_fp = io.BytesIO()
        tts.write_to_fp(audio_fp)
        audio_fp.seek(0)
        audio_base64 = base64.b64encode(audio_fp.read()).decode('utf-8')
        audio_html = f"""
        <audio autoplay>
            <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mpeg">
        </audio>
        """
        st.components.v1.html(audio_html, height=0)
    except Exception as e:
        st.error(f"èªéŸ³ç”Ÿæˆå¤±æ•—ï¼š{e}")

# --- 2. è¨­å®šå´é‚Šæ¬„ (Sidebar) ---
st.sidebar.header("âš™ï¸ æ ¸å¿ƒè¨­å®š")

# API Key è¨­å®š
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
except KeyError:
    api_key = None
if not api_key:
    st.sidebar.warning("å°šæœªè¨­å®š API Keyï¼è«‹åœ¨ Streamlit Cloud Secrets ä¸­è¨­å®šã€‚")
    api_key = st.sidebar.text_input("æˆ–åœ¨æ­¤è‡¨æ™‚è¼¸å…¥æ‚¨çš„ Google API Keyï¼š", type="password")

# è§’è‰²ç‰¹æ€§è¨­å®š
default_persona = "ä½ æ˜¯ä¸€ä½çŸ¥è­˜æ·µåšã€æ¨‚æ–¼åŠ©äººçš„ AI åŠ©ç†ã€‚"
st.sidebar.subheader("ğŸ­ è§’è‰²ç‰¹æ€§è¨­å®š")
persona_prompt = st.sidebar.text_area("è«‹è¼¸å…¥ AI çš„è§’è‰²æè¿° (System Prompt)ï¼š", value=default_persona, height=200)

# æ¨¡å‹é¸æ“‡
model_name = st.sidebar.selectbox("é¸æ“‡æ¨¡å‹ (Vision Pro æ”¯æ´åœ–ç‰‡è¾¨è­˜)", ("gemini-1.5-pro-latest", "gemini-1.5-flash-latest"))

# èªéŸ³åŠŸèƒ½è¨­å®š
st.sidebar.subheader("ğŸ”Š èªéŸ³è¨­å®š")
tts_enabled = st.sidebar.toggle("å•Ÿç”¨/é—œé–‰èªéŸ³è¼¸å‡º", value=True)
voice_options = {"å°ç£ - æ¨™æº–å¥³è²": "com.tw", "ç¾åœ‹ - è‹±èªå¥³è²": "us", "è‹±åœ‹ - è‹±èªå¥³è²": "co.uk"}
selected_voice_name = st.sidebar.selectbox("é¸æ“‡èªéŸ³", list(voice_options.keys()))
selected_voice_tld = voice_options[selected_voice_name]

# --- 3. ä¸»æ‡‰ç”¨ç¨‹å¼ä»‹é¢ ---
st.title("âœ¨ å¤šåŠŸèƒ½ AI åŠ©ç†")
st.caption("æ”¯æ´æ–‡å­—ã€èªéŸ³è¼¸å‡ºèˆ‡åœ–ç‰‡è¾¨è­˜åŠŸèƒ½")

# --- 4. åˆå§‹åŒ–æ¨¡å‹èˆ‡å°è©± ---
chat = None
if not api_key:
    st.error("âš ï¸ è«‹åœ¨å·¦å´è¨­å®šæ‚¨çš„ Google API Keyã€‚")
elif not persona_prompt.strip():
    st.error("âš ï¸ è§’è‰²çš„ç‰¹æ€§è¨­å®šä¸èƒ½ç‚ºç©ºï¼")
else:
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name=model_name, system_instruction=persona_prompt)
        chat = model.start_chat(history=[])
        st.success("æ¨¡å‹å·²æˆåŠŸè¼‰å…¥ï¼")
    except Exception as e:
        st.error(f"æ¨¡å‹æˆ– API Key è¼‰å…¥å¤±æ•—ï¼š{e}")

# --- 5. å°è©±æ­·å²è¨˜éŒ„ç®¡ç† ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # è™•ç†åœ–ç‰‡é¡¯ç¤º
        if "image" in message:
            st.image(message["image"], width=200)
        st.markdown(message["content"])

# --- (æ–°å¢) åœ–ç‰‡ä¸Šå‚³èˆ‡ç®¡ç† ---
uploaded_image = st.file_uploader("ä¸Šå‚³åœ–ç‰‡é€²è¡Œè¾¨è­˜...", type=["jpg", "jpeg", "png"])
if "image_data" not in st.session_state:
    st.session_state.image_data = None

if uploaded_image:
    st.session_state.image_data = Image.open(uploaded_image)
    st.image(st.session_state.image_data, caption="å·²ä¸Šå‚³åœ–ç‰‡", width=200)

# --- 6. è™•ç†ä½¿ç”¨è€…è¼¸å…¥èˆ‡æ¨¡å‹äº’å‹• ---
if prompt := st.chat_input("è«‹è¼¸å…¥æ–‡å­—æˆ–ä¸Šå‚³åœ–ç‰‡å¾Œæå•..."):
    if chat:
        # æº–å‚™è¦é¡¯ç¤ºå’Œå­˜æª”çš„ä½¿ç”¨è€…è¨Šæ¯
        user_message_to_display = {"role": "user", "content": prompt}
        if st.session_state.image_data:
             user_message_to_display["image"] = st.session_state.image_data
        
        st.session_state.messages.append(user_message_to_display)
        with st.chat_message("user"):
            if st.session_state.image_data:
                st.image(st.session_state.image_data, width=200)
            st.markdown(prompt)

        # æº–å‚™å‚³é€çµ¦æ¨¡å‹çš„å…§å®¹
        model_input = [prompt]
        if st.session_state.image_data:
            model_input.append(st.session_state.image_data)
        
        # æ¸…ç©ºå·²ä¸Šå‚³çš„åœ–ç‰‡ï¼Œé¿å…è·Ÿè‘—ä¸‹ä¸€å‰‡è¨Šæ¯ä¸€èµ·å‚³é€
        st.session_state.image_data = None
        
        # è™•ç† AI å›è¦†
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.markdown("æ€è€ƒä¸­...âœï¸")
            try:
                response = chat.send_message(model_input)
                full_response = response.text
                message_placeholder.markdown(full_response)
                if tts_enabled:
                    text_to_speech_autoplay(full_response, selected_voice_tld)
            except Exception as e:
                full_response = f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"
                message_placeholder.error(full_response)
        
        st.session_state.messages.append({"role": "assistant", "content": full_response})
    else:
        st.warning("è«‹å…ˆå®Œæˆå·¦å´çš„è¨­å®šæ‰èƒ½é–‹å§‹å°è©±ã€‚")